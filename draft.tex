\documentclass{llncs}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{alltt}
\usepackage{xspace}
\usepackage{multirow}
%\pagestyle{plain}
\pagestyle{empty}
\usepackage{xcolor}
\usepackage{algorithm2e}
\usepackage{tikz,pgfplots}
\usepackage{etoolbox}
\usepackage{mathtools}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{listings}
%\usepackage{adjustbox}
%\usetikzlibrary{arrows,calc}
\captionsetup{compatibility=false}
%\usepackage{a4wide}
%\usepackage[margin=40mm, top=35mm]{geometry}

%\usepackage{latexsym}
\usepackage{setspace}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{appendix}
\usepackage{amssymb}
%\usepackage{times}

\usepackage{fancyvrb}
\usepackage[framemethod=tikZ]{mdframed}

%here are alternatives for the times package 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{times}
%-------
%\usepackage{pslatex}
%-------
\usepackage{mathptmx}
\usepackage{mathptm}
%-------
%\usepackage{mathtools}
%\usepackage{newtxmath} 
%\usepackage{newtxtext}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \usepackage{fullpage}

%\usepackage{cancel}
%\usepackage{verbatim}
%\usepackage{chngpage}
%\usepackage{xcolor}
%\usepackage{mathrsfs}


\lstset{language=Java,
	basicstyle=\ttfamily\footnotesize,
	showspaces=false,
	showtabs=false,
	breaklines=true,
	showstringspaces=false,
	breakatwhitespace=true,
	commentstyle=\color{pgreen},
	keywordstyle=\color{blue},
	stringstyle=\color{red},
	basicstyle=\ttfamily
}

\newcommand{\Var}{\mathtt{Var}}
\newcommand{\Exp}{\mathtt{Exp}}
\newcommand{\Cmd}{\mathtt{Cmd}}
\newcommand{\Grd}{\mathtt{Grd}}
\newcommand{\Prg}{\mathtt{Prg}}
\DontPrintSemicolon
\SetKwRepeat{Loop}{Loop\{}{\}}%


\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}

\newcommand{\todo}[1]{{\color{blue}TODO:#1}}
\newcommand{\hide}[1]{}
\newcommand{\defn}{\overset{\triangle}{=}}
\newcommand{\maxi}{m}
\newcommand{\cur}{cur()}
\newcommand{\dom}[1]{\mathsf{dom}(#1)}
\newcommand{\IF}[2]{
	\ifmmode
	\mathbf{if}\ #1 \ \mathbf{then}\ #2
	\else
	\textbf{if}\ #1 \ \textbf{then}\ #2
	\fi}
\newcommand{\ite}[3]{
	 \ifmmode
	 \mathbf{if}\ #1 \ \mathbf{then}\ #2\  \mathbf{else}\ #3
	 \else
	 \textbf{if}\ #1 \ \textbf{then}\ #2\  \textbf{else}\ #3
	 \fi}
\newcommand{\rloop}{
	\ifmmode
	\mathbf{Loop}
	\else
	\textbf{Loop}
	\fi}

\newcommand{\Z}{\mathbb{Z}}

\title{\hspace{-0.1cm}{J-ReCoVer}:~Java~Reducer~Commutativity~Verifier}
\author{}
\institute{}
\hide{
\author{
Yu-Fang Chen\inst{1}\inst{2}
\and
Chang-Yi Chiang\inst{2}
\and
Hsin-Hung Lin\inst{1}
\and
Wei-Tsung Kao\inst{1}
\and
Yean-Fu Wen\inst{2}
\and
Wei-Cheng Wu\inst{1}
}
\institute
{
Institute of Information Science, Academia Sinica, Taiwan
\and
Graduate Institute of Information Management, National Taipei University, Taiwan
}}
\author{}
\institute{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\maketitle

\vspace*{-4mm}\begin{abstract}

The MapReduce framework for data-parallel computation was first proposed by
Google~\cite{dean04} and later implemented in the Apache Hadoop
project. Under the MapReduce framework, a reducer computes output
values from a sequence of input values transmitted over the network. Due to
non-determinism in data transmission, the order in which input values arrive at
the reducer is not fixed. In relation to this, the \emph{commutativity problem}
of reducers asks if the output of a reducer is independent of the order of its
inputs. Indeed, there are several advantages for a reducer to be commutative,
e.g., the verification problem of a MapReduce program can be reduced to the
problem of verifying a sequential program. We present the tool J-ReCoVer (Java
Reducer Commutativity Verifier) that implements effective heuristics for reducer
commutativity analysis. J-ReCoVer is the first tool that is specialized in
checking reducer commutativity. Our experimental results over 118 benchmark
examples collected from open repositories are very positive; J-ReCoVer correctly
handles over 97~\% of them.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-4mm}
\section{Introduction} \label{section:introduction}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

MapReduce belongs among the most popular frameworks for data parallel
computation. A MapReduce program~\cite{dean04} consists of several pairs of
\emph{mappers} and \emph{reducers} running on a machine cluster for handling big
data in parallel. Usually, mappers and reducers are the only components in a
MapReduce program that involve concurrency. Mappers read data from a distributed
database and output a sequence of \emph{key-value} pairs. The elements of the
sequence (i.e., key-value pairs) with the same key are sent to the same reducer
for further processing. Due to scheduling policies and network latency, the same
inputs may arrive at a reducer in different orders in different executions.
Therefore, reducers are typically required to be \emph{commutative}, that is,
the output of a reducer is required to be independent of the order of its
inputs. The problem of checking whether this is indeed the case is known as the
\emph{commutativity problem} of
reducers~\cite{csallner13testing,xiao14mr,ChenHSW15,ChenSW16}.

If a reducer is commutative, it will have the same external behaviour under all
possible schedules, and one then suffices with considering any chosen
interleaving of input values when examining its behaviour instead of having to
consider all of them. By fixing a schedule, the verification problem of a
MapReduce program reduces to the verification problem of a sequential program,
which is known to be much easier than the verification problem of
concurrent~programs.

% More concretely, for the verification of a MapReduce program, we propose to do
% it in two phases. First, ensuring if all reducers are commutative. If some
% reducers are non-commutative, modifying them to commutative ones. Usually, the
% modification is not a difficult task~\cite{xiao14mr}, and can be done without
% affecting their functionality and performance. For example, assume that the
% task of a reducer is to find the name of the person with highest score. Such a
% reducer is non-commutative when the input include two people with the same
% highest score. This reducer can be made commutative, by also comparing the ID
% number of people with the same score. Once all reducers are made commutative,
% we reduce the verification problem to sequential verification by fixing a
% scheduler. In this two-phase approach, the key enabling technique is an
% efficient procedure for checking reducer commutativity.

On the other hand, the non-commutative behaviour of a reducer is often the source
of very tricky bugs. A study conducted by Microsoft investigated the
commutativity problem of $508$ reducers running on their MapReduce
server~\cite{xiao14mr}. These reducers were carefully checked using all
traditional means such as code review, testing, and experiments with real data
for months. Still, five of these programs contained very subtle bugs caused by
non-commutativity (which was confirmed by the programmers).

However, checking reducer commutativity is a difficult problem on its own
right~\cite{ChenHSW15,ChenSW16,ChenLTW17}. Even for a simple case in which all
values are mathematical integers, it is proved undecidable in~\cite{ChenHSW15}.
For the case when all values are machine integers (e.g., 64-bits integers), the
problem is decidable, but the only available algorithm, which was proposed
in~\cite{ChenHSW15} too, is of very high complexity and hence of theoretical
interest only.

In this paper, we present the J-ReCoVer tool (Java Reducer Commutativity
Verifier), which is available at~\verb|http://www.jrecover.tk/|.
%
% A link to J-ReCoVer can be found in the supplementary materials.
%
The tool implements a heuristic approach for checking the commutativity problem
that---despite its simplicity---works very efficiently on a large set of
practical integer reducer programs as shown by our experiments. The main
ingredient of the approach is a reduction from the commutativity problem to an
SMT problem. The reduction is incomplete but sound. It is accompanied with
several heuristics which enable the approach to scale to real-world examples.
For the case when the reducer is not proven commutative, we complement the
approach by using testing to find concrete counterexamples.

We collected benchmarks from open repositories such as GitHub and Bitbucket to
evaluate J-ReCoVer. With the help of a search engine \emph{searchcode.com} over
those repositories, we collected 118 programs. We provide this collection of
programs to other interested researchers as a side contribution of the paper.
Our tool J-ReCoVer is able to correctly analyse all but three of the programs.

%=============================================================================
\paragraph*{Related Work.}
%=============================================================================

The reducer commutativity problem can be reduced to a \emph{program equivalence}
problem. One creates another program $R'$ that first non-deterministically swaps
two consecutive input values and then executes the code of $R$. If $R'$ and $R$
are equivalent, using the fact that all permutations of a list can be obtained
by swapping consecutive list elements finitely many times\footnote{Here is an
example to produce [3;2;5;1;4] from [1;2;3;4;5] by swapping consecutive
elements: [\textbf{1};\textbf{2};3;4;5] $\rightarrow$
[2;\textbf{1};\textbf{3};4;5] $\rightarrow$
[2;3;1;\textbf{4};\textbf{5}]$\rightarrow$
[2;3;\textbf{1};\textbf{5};4]$\rightarrow$
[\textbf{2};\textbf{3};5;1;4]$\rightarrow$ [3;2;5;1;4].}, $R$ can be proved to
be commutative. A series of research works address program equivalence
checking (or closely related topics such as regression verification and
translation validation), cf.
\cite{Pnueli:1998:TV,fedyukovich2015automated,barthe2011relational,KlebanovRuemmerUlbrich2017}
to name a few. 

From a high-level view, checking equivalence of two programs $P$ and $P'$ can be
reduced to a sequential verification problem by executing $P'$ after $P$,
followed by checking whether the two programs always produce the same outputs.
The approach can be made more efficient by finding the
right~\emph{synchronization points} and combining the code of $P$ and $P'$ in an
interleaved manner. A lot of research effort have been invested into finding
good synchronization points. In this work, we propose the \emph{head of the
top-level reducer loop} as the synchronization point suitable for reducer
commutativity analysis. According to our experience, discussed later on, the
reducers usually contain just a single such loop. Moreover, for the case when
there are more top-level loops in a reducer, we propose a way of breaking the 
reducer into several ones to be checked independently.

However, we observe that if one naively reduces the commutativity problem to
an equivalence problem and checks it in a precise manner, many reducers cannot
be verified. Therefore, J-ReCoVer uses an over-approximation of the reducer's
behaviour. This approximation allows for a much more efficient, yet---according
to our experiments---precise enough commutativity analysis.

Our approach can be seen as using some form of \emph{sequentialisation} of the
concurrent behaviour. Sequentialisation is the key approach behind many current
successful approaches for verifying multithreaded
programs~\cite{LalReps:Seq:08,LazyCSeq14}. However, our sequentialisation
approach is specialised for the case of reducers and quite different from what
is used in sequentialisation of multithreaded programs: indeed, in MapReduce
programs there is no notion of threads nor context switches.

%Various forms of sequentialisation are behind further research works too, 
Various forms of sequentialisation are also used in works dealing with the concept 
of \emph{robustness} of event-driven
asynchronous programs~\cite{ahmed2017:robustness} or works dealing with programs
running under some \emph{relaxed memory
models}~\cite{ahmed2013:robustness,AbdullaACLR13,AbdullaACLR12}. However, their
computation models are again quite different from that of reducers, and
their results cannot be directly applied.
Besides verification, another interesting research direction is the
\emph{synthesis} of MapReduce programs~\cite{SmithA16}, which uses commutativity analysis
as a component of its framework.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Notations and Definitions} \label{section:integer-reducers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We use $[n,m]$ to denote the set of integers $\{k\mid n \leq k\leq m\}$ and lift
the equality $=$ operation to tuples in the standard way.

% \begin{equation*}
% \begin{array}{rclcl}
% \multicolumn{3}{l}{v\in \Var\mbox{, and }c \in \Z}&&\textmd{Variable and 
%   Constant}\\
% e \in \Exp    &\ \ \  {\triangleq}\ \ \   & v \mid c \mid \cur \mid e + e \mid
%   e - e \mid e \times e \mid *\mid\ldots & &\textmd{Integer Expression}\\
% g\in \Grd  & {\triangleq}  & e < e \mid not\ g \mid g \wedge g  \mid \ldots& & 
%   \textmd{Guard}\\
% s\in \Cmd  & {\triangleq}  & v:= e \mid out(v) \mid \ite{g}{s}{s} \mid s;s && 
%   \textmd{Command}\\
% p\in \Prg  & {\triangleq}  & s;\rloop\{s\};s&& \textmd{Reducer Program}\\
% \end{array}
% \end{equation*}

\begin{wrapfigure}{r}{3cm}
		\vspace{-0.8cm}

%		\begin{minipage}{0.32\textwidth}
%			\begin{algorithm}[H]
%				$m := \cur$; \;
%				\Loop{}{
%					$t:=\cur$;\;
%					\uIf{ $t > m$}{
%						$m := t$
%					}
%				};
%				$out(m)$\;
%			\end{algorithm}
%			\caption*{(a) max}
%		\end{minipage}
%		\hspace{-0.5cm}
	
	\begin{minipage}{0.3\textwidth}
		\begin{algorithm}[H]
			$s := 0;c:=0$; \;
			\Loop{}{
				$s := s+\cur$;\;
				$c := c+1$
			};
			$o := s/c$;\;
			$out(o)$\;
		\end{algorithm}
	\end{minipage}

% 		\begin{minipage}{0.4\textwidth}
% 			\begin{algorithm}[H]
% 				$a:=*;s := 0; c:=0$;\;
% 				\Loop{}{
% 					$s := s+(\cur-a)^2$; \;
% 					$c := c+1$
% 				};
% 				$o := s/c$;\;
% 				$out(o)$
% 			\end{algorithm}
% 			\caption*{(c) standard deviation}
% 		\end{minipage}

	\caption{A reducer that computes the average value.}
	\vspace{-0.8cm}
	\label{fig:reducer_example}
\end{wrapfigure}

For presentation purposes, we provide a sketch of a highly simplified language
for describing reducers. The language allows us to give examples of reducers and
to discuss our approach for checking their commutativity. Let $\Var$ be a set of
\emph{integer variables}. An \emph{integer expression} in $\Exp$ can either be
a~variable from $\Var$, a constant value, a call to the $\cur$ function that
reads and consumes an input value of the reducer, their combinations over basic
arithmetic operations, or a non-deterministically chosen integer value $*$. A
\emph{command} in $\Cmd$ can be an assignment, a branch statement, a sequence of
commands, or an $out(v)$ statement that outputs the value of $v \in \Var$. A
\emph{reducer program} is defined as $s_1;\rloop\{s_2\};s_3$ where $s_1,s_2,s_3
\in \Cmd$. According to our observation over hundreds  of reducer programs in
open repositories, reducer programs are almost always in this form. The
$\rloop\{s_2\}$ statement enters the loop body to execute $s_2$ repeatedly for
each input element until the entire input list is consumed. An example of a
reducer is shown in Figure~\ref{fig:reducer_example}. In the paper, to simplify
the presentation, we assume that a reducer does never produce any output in the
loop body $s_2$. In the J-ReCoVer tool, an algorithm to deal with the output
inside the loop is implemented (as briefly mentioned at the end of
Section~\ref{sec:prover}).

Some reducers use two (or more) top-level loops to compute the output, possibly
interleaved with some non-looping code. These loops are executed sequentially,
repeatedly iterating over the input list from its beginning. For example, for
calculating the standard deviation, one first computes the average of inputs and
then uses it to compute the final result (using two passes over the input list).
In that case, we suggest to verify the reducer by first partitioning it into two
(or more) reducers, each containing a single top-level loop, and then verifying
these reducers separately.\footnote{Nested loops can be removed by adding
additional branch statements since both the inner and outer loop are over the
same input list. In fact, such a program construct has never occurred in the
examples we have seen.} The top-level loops communicate through shared
variables. After the transformation, reducers corresponding to the second
top-level loop (and possibly further such loops) will work with random initial
values of the shared variable, which over-approximates the original behaviour.
In our experience, the second (or further) top-level loop are usually
commutative even with arbitrary initial shared variable values, and so J-ReCoVer
can be used to handle such reducers.

%For instance, for the case of the standard deviation, the first reducer computes
%the average, and the other reducer performs the rest of the computation. The
%second reducer replaces the average with a non-deterministic value and thus
%``over-approximates'' all possible outputs of the standard deviation
%computation. Equivalently, it computes an output for all possible ``average''
%values. However, this reducer is still commutative, and its commutativity can be verified.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\section{Overview of the J-ReCoVer Tool} \label{sec:overview}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Hadoop, Java;

The input of J-ReCoVer is a reducer program written in Java, which is the most
popular programming language used in the Hadoop MapReduce
framework. The J-ReCoVer tool has three main components, the
\emph{Preprocessor}, the \emph{Prover}, and the \emph{BugFinder}. As the name
suggests, the Preprocessor reads as input a reducer program and performs the
required preprocessing. The goal of Prover is to show that a given reducer is
commutative, and the goal of BugFinder is the opposite. The architecture of
J-ReCoVer can be found in Figure~\ref{fig:overview-jrecover}. The user can input
a reducer program to J-ReCoVer either through our web-interface or use a binary
application installed on his/her own machine.

The \emph{Preprocessor component} first compiles a reducer program to bytecode
and uses the tool Soot to further convert it to the so-called ``Jimple'' format,
which is an intermediate language designed to simplify the analysis of Java
programs. Under the Hadoop MapReduce framework, the permutation of the input is
handled by the scheduler/shuffler component and is affected by issues like
network latency, which are not controllable by programmers. In order to deal
with such issues, we wrote our own dummy Hadoop environment for the reducer as a
part of the Preprocessor component so that the input order of the reducer is now
controlled by J-ReCoVer. Finally, the Preprocessor performs  a program transformation to simplify the analysis. 

%For example, it converts all output commands $out(e)$ inside loops to a special assignment (as explained in Section~\ref{sec:program_trans1}).

\begin{wrapfigure}{r}{7cm}
	\vspace{-8mm}
\centering
	\scalebox{0.7}{
		\begin{tikzpicture}


		%J-ReCoVer
		\node[draw=red!30, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=8cm,fill=red!10,minimum height=7cm] (jrecover) at (5,0) {};
		\node at (5,-.5) {\textbf{J-ReCoVer}};

		%JAVA reducer
		\node[draw=yellow!80, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=0.6cm,fill=yellow!20,minimum height=4cm] (reducer) at (0.5,-1.6) {};
		\node[rotate=270, align = center] at (0.5,-3.6) {Java Reducer};


		%JPreprocessor
		\node[draw=blue!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=3cm,fill=blue!20,minimum height=6.cm] (preprocessor) at (3,-.8) {};
		\node[] at (3,-1.2) {Preprocessor};

		%JPreprocessor->Interface
		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=0.3cm,fill=green!10,minimum height=1.5cm] (interface1) at (1.8,-1.6) {};
		\node[rotate=270, align = center] at (1.8,-2.4) {Web};

		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=0.3cm,fill=green!10,minimum height=3cm] (interace2) at (1.8,-3.6) {};
		\node[rotate=270, align = center] at (1.8,-5) {Installed app.};

		%JPreprocessor->Technologies
		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=2cm,fill=green!10,minimum height=1cm] (soot) at (3.2,-2) {};
		\node at (3.2,-2.6) {Soot};

		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=2cm,fill=green!10,minimum height=1.4cm] (symex) at (3.2,-3.3) {};
		\node at (3.2,-4) {
			\begin{minipage}[t]{0.222\textwidth}
			\centering
			Dummy\\
			Hadoop\\
			Environment
			\end{minipage}		
			};

			\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=2cm,fill=green!10,minimum height=1.2cm] (prog_trans) at (3.2,-5) {};
			\node at (3.2,-5.6) {
				\begin{minipage}[t]{0.222\textwidth}
				\centering
				Program\\
				Transform.
				\end{minipage}
			};

		%JProver
		\node[draw=blue!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=3cm,fill=blue!20,minimum height=5cm] (prover) at (6.5,-0.8) {};
		\node[] at (6.5,-1.2) {Prover};

		%JProver->Technologies
		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=2cm,fill=green!10,minimum height=1.2cm] (z3) at (6.5,-2.4) {};

		\node at (6.5,-3) {
			\begin{minipage}[t]{0.222\textwidth}
			\centering
			Z3 SMT \\
			Solver
			\end{minipage}
		};


		\node[draw=green!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=2cm,fill=green!10,minimum height=1.2cm] (z3) at (6.5,-4.) {};

		\node at (6.5,-4.6) {
			\begin{minipage}[t]{0.222\textwidth}
			\centering
			Live Variable \\
			Analysis
			\end{minipage}
		};

		%JBugFinder
		\node[draw=blue!50, inner sep=0, anchor=north,rounded corners, fill opacity=0.85,text width=3cm,fill=blue!20,minimum height=0.5cm] (learner) at (6.5,-6.2) {};
		\node[] at (6.5,-6.5) {BugFinder};


		%JResults


		\node[rotate=270, align = center] at (9.5,-1) {
			Commutative
		};

		\node[rotate=270, align = center] at (9.5,-3.5) {
			Unknown
		};

		\node[rotate=270, align = center] at (9.6,-6) {
			\begin{minipage}[t]{0.25\textwidth}
			\centering
			Non-Commutative	 \\
			+ Counterexample
			\end{minipage}

		};


		\draw [->] (8,-6.6) -- (9.2,-6.6) ;
		\draw [->] (8,-1.4) -- (9.2,-1.4) ;
		\draw [-] (8,-6.3) -- (8.5,-6.3) --(8.5,-3.5);
		\draw [->] (8,-3.5) -- (9.2,-3.5) ;

		\draw [->] (4.5,-3) -- (5,-3) ;
		\draw [->] (4.5,-6.5) -- (5,-6.5) ;

		\draw [->] (0.8,-4) -- (1.5,-4) ;

		\end{tikzpicture}
	}
		\vspace{-1cm}
	\caption{Overview of the J-ReCoVer tool. }\label{fig:overview-jrecover}
		\vspace{-0.8cm}
	
\end{wrapfigure}

%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{4mm}
%!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

The \emph{BugFinder component} randomly generates pairs of lists. The lists in a
pair are permutations of each other. A concrete counterexample is reported if
inputting any pair of lists from the generated ones to the reducer generates
different results. Our procedure for generating random pairs is quite naive. We
use five different input list of lengths 5, 7, 9, 11, and 13. For each length,
we generate 300 lists and pick uniformly at random one of its permutations.
Although the approach is simple; in practice, it finds counterexamples in all of
our non-commutative benchmarks in a few seconds. 

The \emph{Prover component} reduces the commutativity problem to an SMT
satisfiability problem. From a high-level point of view, we check equivalence
between a reducer program and its variant that has two consecutive inputs
swapped. We show that this can be reduced to a first-order formula and give it
to the SMT solver Z3 for solving. In case that Z3 proves the formula
unsatisfiable, we know that swapping any two consecutive inputs of the reducer
will not change its output. Since all permutations of a list can be obtained by
swapping consecutive elements finitely many times, it follows that the reducer
outputs the same value for all permutations of the same list of inputs. In this
case, J-ReCoVer stops and reports that the reducer is commutative.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-2mm}
\section{The Preprocessor and the Prover} \label{sec:preprocessor_prover}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Before entering the Prover component, the Preprocessor first performs a
program transformation to simplify the verification task
(Section~\ref{sec:program_trans1}). The output of the preprocessor is a
commutativity-equivalent reducer program. The algorithm of the Prover is then
explained in Section~\ref{sec:prover}. 

%=============================================================================
\vspace*{-2mm}
\subsection{The Program Transformation in the Preprocessor}
\label{sec:program_trans1}
\vspace*{-1mm}
%=============================================================================

%-----------------------------------------------------------------------------
%\paragraph*{Handling the access to $\cur$ before entering the loop.}
%-----------------------------------------------------------------------------

\begin{wrapfigure}[11]{r}{3.5cm}
	\vspace{-18mm}
	\begin{algorithm}[H]
		\;\;$m := \cur + 10$; \;
		\Loop{}{
			$t:=\cur$\;
			\uIf{ $t> m$}{
				$m := t$ \;
			}
		};
		$out(m)$\;\;
	\end{algorithm}
	\vspace{-0.8cm}
	\caption{The max$^+$ reducer with input before the main loop.}
	\vspace{-11mm}
	\label{fig:reducer_max1}
\end{wrapfigure}	

%	\begin{figure}[t]
%		\begin{minipage}{0.4\textwidth}
%			\begin{algorithm}[H]
%				\;\;$m := \cur + 10$; \;
%				\Loop{}{
%					$t:=\cur$\;
%					\uIf{ $t> m$}{
%						$m := t$ \;
%					}
%				};
%				$out(m)$\;\;
%			\end{algorithm}
%			\caption*{(a) Reducer max$^+$}
%		\end{minipage}
%		\begin{minipage}{0.6\textwidth}
%			\begin{algorithm}[H]
%				$s:=*;$\;
%				\Loop{}{
%					\uIf{$s=1$}{$m := \cur + 10; s:= 2$}
%					\uElse{
%						$t:=\cur$\;
%						\uIf{ $t > m$}{
%							$m := t$ \;
%						}
%					}
%				};
%				$out(m)$
%			\end{algorithm}
%			\caption*{(b) Reducer max$^{+\mathtt{fix}}$}
%		\end{minipage}
%		\caption{Reducer examples}
%		\label{fig:reducer_max}
%	\end{figure}

In real-world reducers, it is often the case that the $s_1$ part of the reducer
reads from the input. Since our reduction of the commutativity problem to SMT
solving, which is presented in Section~\ref{sec:prover}, concentrates on the
influence of the input on the loop $s_2$ only, we need to transform the reducer
such that any input happens in the loop only. 

To illustrate the issue, we consider the reducer shown in
Figure~\ref{fig:reducer_max1}.
%
The reducer presented in the figure remembers the first input value in the
variable $m$, increases its value by 10, and then updates its value to bigger
ones if any occur in the loop.  The main loop of the reducer is commutative in
this case, but the reducer is not commutative. A counterexample can be easily
found. With the list $[1,2,3,4,5]$ and its permutation $[5,4,3,2,1]$ as the
inputs, the reducer outputs $11$ and $15$, respectively.

\begin{wrapfigure}[12]{r}{5.3cm}
	\vspace{-10mm}
	\begin{algorithm}[H]
		$s:=1;$\;
		\Loop{}{
			\uIf{$s=1$}{$m := \cur + 10; s:= 2$}
			\uElse{
				$t:=\cur$\;
				\uIf{ $t > m$}{
					$m := t$ \;
				}
			}
		};
		$out(m)$
	\end{algorithm}	
	\vspace{-2mm}
	\caption{The max$^{+\mathtt{fix}}$ reducer.}
	\vspace{-4mm}
	\label{fig:reducer_max2}
\end{wrapfigure}

Our transformation will handle the example from Figure~\ref{fig:reducer_max1} as
follows.
%
We move the prefix $s_1$ into the loop body and use a new variable $s$ to force
that the execution of $s_1$ is always before the original loop body. The result
after the transformation is demonstrated in Figure~\ref{fig:reducer_max2}. The
new reducer program has the same inputs/outputs as the original one. Therefore,
if the new reducer is commutative, the original one~is~also~commutative.

% TV: The below was removed since the requirements have not even be stated.
%
% It also satisfies all assumptions required for the Prover component: (1) the
% commands before entering the loop do not have any $\cur$ expression, (2) the
% $out(v)$ command does not occur inside the loop body.

%	\begin{wrapfigure}{r}{9cm}
%		\centering
%		\begin{minipage}{0.8\textwidth}
%			
%			\begin{algorithm}[H]
%				$s'_0;s:=*;$\;
%				\Loop{}{
%					\lIf{$s=1$}{ $x_{i_1} := \cur; s'_1; s:=2$}
%					\lElseIf{ $s =2$}{ $x_{i_2} := \cur; 
%                                           s'_2; s:=3$}
%					\lElseIf{ $s = 3$}{$\ldots$}
%					\lElseIf{ $s = m$}{$x_{i_m} := \cur; 
%                                          s'_m; s:=m+1$}
%					\lElse{ $s_2$}
%				};$s_3$\;
%			\end{algorithm}
%		\end{minipage}
%		\caption{The second transformation task}
%		\label{fig:general_program_transformation}
%        \end{wrapfigure}

% In general, the problem with the multiple inputs before the loop can be handled
% as follows. Given a reducer $c_0;x_{1}{:=} \cur;c_1; \ldots;
% x_{m}{:=}\cur;c_m;\rloop\{s_2\};s_3$, where $m$ inputs are read before the loop
% and $\cur$ does not occur in $c_0,c_1,\ldots, c_m$.  In the transformed reducer,
% the part before the loop is now $c_0;s:=1$. The loop body contains several
% branch statements. For all $j \in [1,m]$, we add a branch statement
% $\IF{s=j}{x_{j}:=\cur; c_j; s:=s+1}$.  We also add $\IF{s=m+1}{s_2}$ for the
% original loop body.

In general, the problem with the input before the loop can be handled as
follows, including the case where $\cur$ occurs multiple times in $s_1$. Assume
that the $s_1$ part of the reducer $s_1;\rloop\{s_2\};s_3$ has the form
$c_0;x_{1}{:=} \cur;c_1; \ldots; x_{m}{:=}\cur;c_m$ where $\cur$ does not occur
in $c_0,c_1,\ldots, c_m$. In the transformed reducer, the part before the loop
will be $c_0;s:=1$, and the loop body will contain several new branch
statements. In particular, for all $j \in [1,m]$, we add the branch statement
$\IF{s=j}{x_{j}:=\cur; c_j; s:=s+1}$. Moreover, we transform the original loop
body into the branch $\IF{s=m+1}{s_2}$.

%-----------------------------------------------------------------------------
%\paragraph*{Handling output inside the loop body} 
%-----------------------------------------------------------------------------

%Another problem for our reduction to SMT is the fact that the reducer program
%can perform the output command $out(e)$ inside the loop body $s_2$. Since our
%SMT-based commutativity checking presented later on will be based on examining
%possible values of the variables that appear in the $s_2$ loop body only (these
%values then determine the output performed in $s_3$), we will replace each such
%$out(e)$ command by the assignment $v:=e$ for a fresh variable $v$. This makes
%the value that will be output visible for our analysis. The fact that we loose
%the output command does not matter since---as already said---we will not track
%the output commands but values of the variables that determine the value of the
%output.  Notice that the value of $v$ stays the same from the point it has been
%assigned a value until the end of the loop body $s_2$. If the value that $v$ can
%have at the end of $s_2$ does not change for any permutation of the input lists,
%we know that the reducer is commutative wrt all output values produced inside
%the loop body $s_2$.

%=============================================================================
\subsection{The Prover: Reduce Commutativity Checking to SMT Solving}
\label{sec:prover}
%=============================================================================

After the transformation described above, the reducer $s_1;\rloop\{s_2\};s_3$
never calls the $\cur$ function in the $s_1$ part before entering the loop.
Further, we assume w.l.o.g. that the reducer reads exactly one input in one loop
iteration. When multiple reads from the input occur in a single execution path from the begin to the end of
the loop body, we can use additional variables and branch statements to break the path into several
auxiliary ones, each reading just once.

The command $s_2$
can be viewed as a function $F$ that reads the values of all variables and the
current input before executing $s_2$ and outputs the values of all variables
after $s_2$. Formally, the function $F(n,x_1,x_2,\ldots,x_k): \Z^{k+1}
\rightarrow \Z^k$ returns a tuple of values $x_1',x_2',\ldots,x_k'$ where $n$ is
the current input value of the reducer, $x_i$ and $x_i'$ are the values of the
variables before and after the execution of $s_2$, respectively, for
$i\in[1,k]$. The construction of $F$ from $s_2$ can be done in the standard way.

We reduce the reducer commutativity verification to checking validity of the
following formula for all possible values of $n_1,n_2, x_1,x_2,\ldots,x_k$:
\begin{equation} F(n_1, F(n_2,x_1,x_2,\ldots,x_k)) = F(n_2,
F(n_1,x_1,x_2,\ldots,x_k) ). \label{eq:commu} \end{equation} Intuitively, the
formula says that starting from the same initial valuations of variables and
with two different input orders, $[n_1;n_2]$ and $[n_2;n_1]$, the values of all
program variables are the same after we execute the loop body twice. The first
execution reads $n_1$ and then reads $n_2$. The other execution reads the two
inputs in the reverse order. Since any permutation of the input can be obtained
by a sequence of permutations of neighbouring inputs, the validity of
Formula~\ref{eq:commu} implies that the permutations will not change the final
variable valuation and hence the output in $s_3$. 

Consider the reducer computing the average value
(Figure~\ref{fig:reducer_example}) as an example. The reducer has two variables
$s$ and $c$. We get that $F_{average}(n,s,c)=(s+n, c+1)$. In this case,
Formula~\ref{eq:commu} is valid since $F_{average}(n_1, F_{average}(n_2,s,c))
=F_{average}(n_1, s+n_2, c+1)= (s+n_1+n_2,c+2)=F_{average}(n_2, s+n_1,
c+1)=F_{average}(n_2, F_{average}(n_1,s,c))$. This implies that the reducer is
commutative.


% In the example of ``average'', the values of $s$ and $c$ are the same no
% matter the reducer first reads $n_1$ and then $n_2$ or reads the two values in
% the swapped order.  So it computes the same value for the input
% [1;2;\textbf{3};\textbf{4};5] and any other input with two consecutive values
% being swapped, e.g., [1;2;4;3;5].  The swap operation can be applied
% arbitrarily many times to produce all possible permutations of the input.  It
% follows that that starting from the same variable valuation, the loop ends
% with the same valuation for any permutation of input values, e.g., the reducer
% will output the same value for [1;2;3;4;5], [1;2;4;3;5], [1;4;2;3;5],
% [4;1;2;3;5], etc.  Recall that the first program transformation task stores
% all output values in variables that will stay unchanged until the end of the
% loop. The validity of Equation~(\ref{eq:commu}) also implies that the
% execution of the loop produces the same sequence of outputs.
% 
% We explain why that the validity of Equation~(\ref{eq:commu}) is sufficient to
% prove the reducer $s_1;\rloop\{s_2\};s_3$ commutative. Notice that $s_1$ does
% not read from the input (assumed at the beginning of this subsection). The
% execution of $s_1$ is deterministic in the sense that from the same initial
% valuation, it outputs the same sequence of values and ends at the same
% valuation. For the execution of $\rloop\{s_2\}$, from the validity of
% Equation~(\ref{eq:commu}), any permutation of input values leads the reducer
% to the same final valuation and the same sequence of outputs at the end of the
% loop.  Before executing the commands $s_3$, all inputs have been read (the
% loop exit condition) already. Similar to the case of $s_1$, $s_3$ does not
% read from the input and hence the execution of $s_3$ is deterministic. It
% follows that for all permutations of inputs, the reducer outputs the same
% sequence of values.
% 

%-----------------------------------------------------------------------------
\paragraph{A note on dealing with output in the main loop.} 
%-----------------------------------------------------------------------------

So far we have assumed that there was no output in the main loop and mentioned
that this restriction is lifted in J-ReCoVer. Due to space restrictions, a
proper explanation of the way of handling this issue is beyond the scope of this
paper, but we give at least a brief sketch of the solution. In particular, the
Preprocessor performs one more transformation which adds an assignment $v := e$
for every $out(e)$ statement in the main loop where $v$ is a fresh variable
assigned just once in the loop body. This makes the output visible for our
analysis since $v$ appears in Formula~\ref{eq:commu}. The Prover then makes an
additional check whether the value of $F(n, x_1,x_2,\ldots,x_k)$ projected on
$v$ stays the same for any input value $n$ and any initial values of the
variables $x_i$.


%=============================================================================
\subsection{An Optimisation by Live Variable Analysis}
\label{section:optimizations}
%=============================================================================

We now explain how a simple live variable analysis is used in J-ReCoVer to
significantly improve the precision of commutativity checking.

In our initial experiments, we realised that Formula~\ref{eq:commu} is a
condition that is too strong for the reducer to be commutative. To illustrate
the issue, we present a simple example. In the loop body, the input is first
stored in a variable $t$ and this is then assigned to $s$, i.e., $t:=\cur;s:=s+t$.
After the loop, the value of $s$ is output. In this case, the $F$ function
returns the updated values of both $s$ and $t$ after the execution of the loop
body. Observe that $F(c_1, F(c_2,s,t)) = (s+c_1+c_2, c_1)$ and $F(c_2, F(c_1,s,t))
= (s+c_1+c_2, c_2)$. It follows that Formula~\ref{eq:commu} is invalid. The second
component of the returned tuples, which causes the invalidity, corresponds to
the value of $t$ after executing the loop body twice. Their values are $c_1$ and
$c_2$, respectively, in $F(c_1, F(c_2,s,t))$ and $F(c_2, F(c_1,s,t))$. However,
in this case, the value of $t$ will not affect the output of the reducer.

To handle the above issue, we perform a simple backward live variable analysis
to collect all variables whose value may propagate to the output command after
the loop execution. Only these variables are then required to be equivalent. In
our evaluation, the ratio of reducers that our approach can successfully analyse
is significantly increased---in particular, from $6.8~\%$ to $97.5~\%$---by
using this optimisation. 

% Without loss of generality, we assume there is only one output command after the loop. Then the code after the loop (i.e., the $s_3$ part of the reducer) can only be in the form of Figure~\ref{fig:nested_out}.
% We unfold all concatenation of commands, so now the commands $c_1\ldots c_n$ are either assignment commands $w:=e$ or branch command $\ite{g}{c'_1}{c'_2}$, and the only output command stays in the $m$-th layer of the branch command after $c_i$. For the case that $m=0$, the entire branch command in Lines 2-6 of Figure~\ref{fig:nested_out} is replaced with $out(v)$.
% 
% The data flow analysis algorithm works as follows.
% A set $V_3$ whose value is initially a singleton set $\{v\}$ is used to remember the variables that might flow to the output command $out(v)$ in $s_3$ (in Figure~\ref{fig:nested_out}).
% The commands and guards will be inspected in the following order $c_{n}$,$\ldots$,$c_{i+1}$, $g_m$, $g_{m-1}$, $\ldots$, $g_1$, $c_i$, $\ldots$, $c_2$, $c_1$. For the case that a guard $g_j$ for $j\in [1,m]$ is being processed, we simply add all variables occurred in $g_j$ to $V_3$.
% For the case that a command $c_j$ for $j\in [1,n]$ is being processed, we need to handle two different cases:
% \begin{itemize}
% 	\item $c_j$ is an assignment $w:=e$ and $w\in V_3$: all variables in $e$ are added to $V_3$.
% 	\item $c_j$ is a branch $\ite{g}{c'_1}{c'_2}$: the algorithm starts from the same set $V_3$ and processes $c'_1$ and $c'_2$ individually and independently (in a similar manner) to obtain $V_3^1$ and $V_3^2$. After that, the algorithm takes their union $V_3^1\cup V_3^2$ as the new value of $V_3$.
% \end{itemize}
% After the entire $s_3$ is being processed we get the set of important variables that might affect the outputs that happen in $s_3$.
% Then we modify the Equation~(\ref{eq:commu}) to the one below
% \begin{equation}
% F(n_1, F(n_2,x_1,x_2,\ldots,x_k) )=_{PosF(V_2\cup V_3)} F(n_2, F(n_1,x_1,x_2,\ldots,x_k) )
% \label{eq:commu2}
% \end{equation}
% The function $PosF(X)$ returns the corresponding positions of variables in $X$ in the output of $F(n,x_1,\ldots,x_k) $. E.g., if $X = \{x_1,x_4,y\}$, where $y\notin \{x_1,\ldots,x_k\}$, then $PosF(X)=\{1,4\}$.
% The use of Equation~(\ref{eq:commu2}) is critical to the success of our approach.
 
% \subsection{Computing the $F$ function using symbolic execution with an efficient data structure}
% \label{section:opt2}
% 
% The computation of $F$ in Equation~(\ref{eq:commu2}) can be done in several different ways. For example, one can construct a formula in the style of bounded model checking. Here we apply \emph{symbolic execution} to generate $F$. Below we first review the standard symbolic execution algorithm and then explain how we use it to construct the formula $F$.
% 
% 
% First, we define the set $\Var_0=\{v_0 \mid v \in \Var \}\cup \{c_0\}$ as the set of initial symbolic values of all variables, where $c_0$ is used to denote the symbolic value from the input.
% A \emph{symbolic state} is a triple $\langle pc, val, cmds \rangle$, where the \emph{path condition} $pc$ is a guard in $\Grd$ over $\Var_0$, the \emph{symbolic valuation} is a mapping from variables in $\Var$ to an expression in $\Exp$ over $\Var_0$, and $cmds\in \Cmd$ is the remaining commands to be executed. The \emph{initial symbolic state} is $\langle \true, val_0, s_2\rangle$, where $val_0(v) = v_0$ for all $v\in\Var$ and $s_2$ is the loop body of the reducer.
% One can compute the next symbolic state of $\langle pc, val, c;cmds \rangle$ according to the following transition rules. Recall that $c$ is either in the form of $v:= e$ or $\ite{g}{c_1}{c_2}$ after the program transformation tasks are performed:
% \begin{enumerate}
% 	\item If $c$ is $v:= e$, the next symbolic state is $\langle pc, val[v \rightarrow val(e) ], cmds \rangle$.
% 	\item If $c$ is $\ite{g}{c_1}{c_2}$, the next symbolic states are $\langle pc\wedge g, val, c_1.cmds \rangle$ and $\langle pc\wedge not\  g, val, c_2.cmds \rangle$.
% \end{enumerate}
% 
% Here we lift the $val$ function from variables to expressions in the standard way and $val[v \rightarrow val(e) ]$ is obtained by reassigning the value of $v$ in $val$ to $val(e)$. The execution from a symbolic state terminates when its path condition is conflict or the commands to be executed become empty, i.e., all commands have been processed. So far it is standard.
% 
% For the loop body $s_2$, symbolic execution is guaranteed to terminate because there exist no commands in $s_2$ that may lead to infinite computations.
% When the execution terminates, we collect all states with empty commands $\langle pc, val, \emptyset \rangle$ as a set $T$ and use them to create the function $F$ in Equation~(\ref{eq:commu2}).
% First, we create for each variable $x\in\Var$ a formula $f_x$ whose value is $\bigvee_{\langle pc, val, \emptyset \rangle \in T} (pc \wedge val(x))$.
% The function $F(n,x_1,x_2,\ldots,x_k)$ simply returns the tuple $(f_{x_1},f_{x_2},\ldots, f_{x_k})$.
% 
% However, doing symbolic execution in a naive way can be extremely inefficient.
% The length of the formula $val(v)$ can grow exponentially w.r.t. the input commands. For example, consider a simple command $u:=x+y;u:=u+u;u:=u+u$, each execution of $u:= u+ u$ will double the length of the expression representing the symbolic value of $u$. More concretely, after the execution of $u:=x+y$, the symbolic value of $u$ is $x_0+y_0$. After the two executions of $u:=u+u$, the value of $u$ changes to $x_0+y_0+x_0+y_0$ and $x_0+y_0+x_0+y_0+x_0+y_0+x_0+y_0$, respectively. One way to alleviate the problem is to apply formula simplification algorithms, e.g., those implemented in Z3.
% Here we propose in a very simple alternative solution that works quite well in our reducer benchmarks.
% 
% We use a more efficient data structure to store symbolic values. At a high level, in a symbolic state, we count the number of occurrences of each symbolic values in $\Var_0$ and update the count when operations such as $+$ and $-$ is applied. For other operations $x\odot y$, we create a new symbolic expression $val(x) \odot val(y)$ and count its number of occurrence as one.
% More concretely, we use a map $sv_x:\Exp\rightarrow \mathbb{N}$ (symbolic value of $x$) to remember the number of occurrences of each expression in $x$. We have $val(x)= (\Sigma_{z\in \dom{sv_x}} (z\times sv_x(z)) )$, where $\dom{sv}=\{e\mid sv(e)\neq 0\}$.
% Initially, $sv_x(x_0) = 1$ and $sv_x (e) =0$ for all $e\neq x$. Assume that the symbolic value of $x,y$ are $sv_x,sv_y$ in the current symbolic state. The symbolic value $sv'_x$ of $x$ after the assignment $x:=p\circ q$ is defined as follows.
% 
% \begin{itemize}
% 	\item For the case that $\circ \in\{+,-\}$, we have $sv'_x(z) = sv_p(z)\circ  sv_q(z)$.
% 	\item For the case that $\circ \notin\{+,-\}$, we define $sv'_x(val(p) \circ val(q)) =1$ and $sv'_x(e) = 0$ for all $e\neq val(p) \circ val(q)$.
% \end{itemize}
% To make the definition complete for our simple reducer program commands, we further define (I) $sv_{\cur}(c_0) =1$ and $sv_{\cur}(e)=0$ for $e\neq \cur$, (II) $sv_{n}(1) =n$ and $sv_{n}(e)=0$ for $e\neq 1 \wedge n\in \Z$.
% This data structure is efficient for strong symbolic values of reducer programs mainly for reason that the operations $+$ and $-$ are quite heavily used in such programs.
% Here we give a tiny example. Initially, $sv_x(x_0)=1$. After the commands $x:=x*x;x:=x+x$, we get $sv_x(x_0*x_0)=1$ and $sv_x(x_0*x_0)=2$, respectively.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation} \label{section:exp}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

J-ReCoVer is implemented in Java and built on top of Soot 2.5.0 and Z3 4.7.1. We
ran J-ReCoVer on a virtual machine with 4GB of memory running Ubuntu 16.04.5 LTS
on a server with AMD Opteron 6376 CPU. 

\begin{wraptable}[7]{r}{40mm}
	\vspace{-8mm}
	\caption{Size of the reducers.}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& Line & Variable & Branch\\
		\hline
		Min. & 5 & 4 & 0\\
		Avg. & 20.5 & 14.7 & 1.2\\
		Max. & 58 & 37 & 5\\
		\hline
	\end{tabular}

	\label{tab:benchmark}
	\vspace{-5mm}

\end{wraptable} 

%-----------------------------------------------------------------------------
\paragraph*{Benchmark collection} 
%-----------------------------------------------------------------------------


In order to properly evaluate the performance of J-ReCoVer, we used the search
engine \emph{searchcode.com} to collect Java programs containing the key strings
``public void reduce'' or ``protected void reduce''. Since there is an upper
bound on the number of results returned from the search engine, we added
different search filters in order to get more data. We tried all $12$
combinations of six filters on the code length $\{<50$, $ 50\sim 250$, $250\sim
450$, $450\sim 650$, $650\sim 850$, $850\sim 1050$, $1050\sim 1250\}$ and two
filters for data sources $\{\url{github.com}, \url{bitbuckect.com}\}$. In total,
we got $11,346$ Java programs. We excluded cases that were not Hadoop MapReduce
reducer programs (those do not import the Hadoop library, do not extend or
implement the reducer interface) and obtained $1,273$ examples. We further
removed duplicates, those that could not be compiled, and those with non-numerical data types (e.g., strings). We obtained
$118$ reducers as the final benchmarks. Table~\ref{tab:benchmark} contains more
details of the considered reducer functions.


%-----------------------------------------------------------------------------
\paragraph*{Results} 
%-----------------------------------------------------------------------------

J-ReCoVer successfully handled $115$ cases ($97.5~\%$) out of the considered
ones. Among them, $106$ cases are commutative, while $9$ are not. The analysis time ranged between $9.8$ and $8.6$ seconds. On average,
$72~\%$ of the execution time was spent in compiling Java source code to
bytecode, which is the input of the Soot tool. Further, $27~\%$ of the execution
time was spent in the Preprocessor, in which Soot is used to transform Java
bytecode to Jimple and perform the program transformation. The time spent in
Solver is quite limited ($<1~\%$) since the real-world integer reducer programs
are usually not that big. 

There is no other tool that could handle the reducers as they are. Perhaps some
other tools could be applied on the transformed programs, but the
transformation would still be needed, and our SMT-based back-end verifier (the
Solver) turned out to work efficiently. Hence, we did not feel a need to replace
it by another verification tool. Of course, in the future, this can be done if
need be.

J-ReCoVer failed in three cases out of the considered ones because the three
reducers use more complicated control structures than what J-ReCoVer currently
supports. Namely, they use a branch statement before entering the loop, i.e.,
they have the form of
$\ite{g}{(s_1;\rloop\{s_2\};s_3)}{(s'_1;\rloop\{s'_2\};s'_3)}$. In theory, such
a program can be handled by more sophisticated program transformation. For
example, we can merge the two loops and push the outer branch condition into the
merged loop. Extensions of J-ReCoVer to be able to handle such constructions,
together with a support for more data types, belong among our future works.

%\begin{wrapfigure}{r}{9cm}
%	\begin{tabular}{|c|c|c|c||c|c|c|}
%		\hline
%		&Compile &Prepossesor &Prover & Lines & Variables & If-branches\\
%		\hline
%		Min. &6.22   &2.15        &0.032 & 5 & 4 & 0\\
%		Avg. &6.54   &2.44        &0.046 & 20.5 & 14.7 & 1.2\\
%		Max. &7.28   &3.06        &0.101 & 58 & 37 & 5\\
%		\hline
%	\end{tabular}
%	\caption{Time in each step, size of the reducers}
%\end{wrapfigure} 

% For the optimization based on live variable analysis
% (Section~\ref{section:optimizations}), we evaluate them based on real-world
% benchmark sets collected from open repositories (118 examples). The difference
% between the version with and without this optimization is very clear. The
% results are presented in table~\ref{tab:opt1}. The first column is the result
% without optimization and the second column is the result with optimization.
% The precision of the analysis is improved from $6.8\%$ to $97.5\%$.  However,
% this new program transformation task is not implemented in J-ReCoVer yet.
%
% If we look into scrutiny, we failed to verify any example using
% Equation~(\ref{eq:commu}). The reason is that when Soot converts a Java
% program to the Jimple format, it always uses a temporary variable to store the
% value of $\cur$ in the loop body (similar to the example in
% Figure~\ref{fig:reducer_opt}). We tried a simpler heuristics approach that
% only ignores the temporary variables and the result is not as good as using
% live variable analysis, because the values of the temporary variables often
% also propagate to other variables.

%\begin{table}[htb]
%	\centering
%	\begin{tabular}{|l|l|l|}
%		\hline
%		&W/O optimization	& With optimization\\
%		\hline
%		\hline
%		Commutative& 0&106\\
%		\hline
%		Non-commutative&8&9\\
%		\hline
%		Unknown&110&3\\
%		\hline
%		Precision& 6.8\% & 97.5\%\\
%		\hline
%		
%	\end{tabular}
%
%        \caption{The improvement of precision using data flow analysis. The row
%        ``Precision'' is calculated as the number of examples that J-ReCoVer
%        returns commutative or non-commutative divided by the total number of
%        example.}
%
%	\label{tab:opt1}
%\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{splncs-sorted}
\bibliography{refs}

\input{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
